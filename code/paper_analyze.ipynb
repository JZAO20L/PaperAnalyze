{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 论文解析/分析\n",
    "1. 读pdf\n",
    "2. LLM总结信息&结构化输出\n",
    "3. LLM分析适配性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "! pip install pydantic langchain langchain-community PyPDF2 python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Tongyi\n",
    "import os\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Dashscope key\n",
    "# 加载 .env 文件\n",
    "load_dotenv()\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "# print(dashscope_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读写文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取指定文件夹中的所有 PDF 文件内容\n",
    "def read_papers_from_folder(folder_path):\n",
    "    papers = []\n",
    "    \n",
    "    # 获取所有 PDF 文件路径\n",
    "    pdf_files = [filename for filename in os.listdir(folder_path) if filename.endswith(\".pdf\")]\n",
    "    \n",
    "    # 使用 tqdm 包裹 pdf_files 列表，显示进度条\n",
    "    for filename in tqdm(pdf_files, desc=\"Reading PDFs\", unit=\"file\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            reader = PdfReader(file_path)\n",
    "            paper_content = \"\"\n",
    "            \n",
    "            # 遍历每一页并提取文本\n",
    "            for page in reader.pages:\n",
    "                paper_content += page.extract_text()\n",
    "            \n",
    "            papers.append(paper_content)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 捕获异常并打印错误信息\n",
    "            tqdm.write(f\"Error reading {filename}: {e}\")  # 使用 tqdm.write 避免干扰进度条\n",
    "    \n",
    "    return papers\n",
    "\n",
    "# 将分析结果保存到 JSON 文件中\n",
    "def save_results_to_json(results, output_file):\n",
    "    # 创建父目录（如果不存在）\n",
    "    # exist_ok=True 表示如果目录已经存在，函数不会抛出异常，而是直接返回\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    # 写入 JSON 文件\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于分析的LLM类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    定义论文信息的结构化输出格式。\n",
    "    \"\"\"\n",
    "    title: str = Field(description=\"Title of the paper\")\n",
    "    model_type: str = Field(description=\"Model type of the method, black box or white box\")\n",
    "    model_names: List[str] = Field(description=\"List of names of the models used in the method\")\n",
    "    method_description: str = Field(description=\"Description of the attack method\")\n",
    "    main_result: str = Field(description=\"Main result of the paper\")\n",
    "\n",
    "class AnalyzeLLM:\n",
    "    def __init__(self, model_name, api_key):\n",
    "        # 初始化大语言模型\n",
    "        self.llm = Tongyi(model=model_name, api_key=api_key)\n",
    "        \n",
    "        # 使用 PydanticOutputParser 来解析结构化输出\n",
    "        self.output_parser = PydanticOutputParser(pydantic_object=PaperInfo)\n",
    "        \n",
    "        # 定义提示模板，用于引导模型生成结构化输出\n",
    "        self.parse_prompt_template = PromptTemplate(template=\"\"\"\n",
    "        Analyze the following paper content and extract structured information:\n",
    "        {content}\n",
    "        \n",
    "        Please provide the output in the following format:\n",
    "        {format_instructions}\n",
    "        \"\"\", input_variables=[\"content\"], partial_variables={\"format_instructions\": self.output_parser.get_format_instructions()})\n",
    "    \n",
    "    def analyze(self, content: str):\n",
    "        \"\"\"\n",
    "        分析论文内容并提取结构化信息。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 构造提示\n",
    "            prompt = self.parse_prompt_template.format(content=content)\n",
    "            \n",
    "            # 调用大语言模型获取响应\n",
    "            response = self.llm.invoke(prompt)\n",
    "            if not response or not isinstance(response, str):\n",
    "                raise ValueError(\"从模型接收到的响应无效。\")\n",
    "            \n",
    "            # 解析模型输出为结构化数据\n",
    "            structured_output = self.output_parser.parse(response)\n",
    "            \n",
    "            return structured_output\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 捕获异常并返回错误信息\n",
    "            raise RuntimeError(f\"分析论文时发生错误：{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文版\n",
    "class PaperInfo_cn(BaseModel):\n",
    "    \"\"\"\n",
    "    定义论文信息的结构化输出格式。\n",
    "    \"\"\"\n",
    "    title: str = Field(description=\"论文标题\")\n",
    "    model_type: str = Field(description=\"方法的模型类型，【黑盒】或【白盒】\")\n",
    "    model_names: List[str] = Field(description=\"方法中使用的模型名称列表\")\n",
    "    method_description: str = Field(description=\"攻击方法的描述\")\n",
    "    main_result: str = Field(description=\"论文的主要结果\")\n",
    "\n",
    "class AnalyzeLLM_cn:\n",
    "    def __init__(self, model_name, api_key):\n",
    "        # 初始化大语言模型\n",
    "        self.llm = Tongyi(model=model_name, api_key=api_key, streaming=True)\n",
    "        \n",
    "        # 使用 PydanticOutputParser 来解析结构化输出\n",
    "        self.output_parser = PydanticOutputParser(pydantic_object=PaperInfo_cn)\n",
    "        \n",
    "        # 定义提示模板，用于引导模型生成结构化输出\n",
    "        self.parse_prompt_template = PromptTemplate(template=\"\"\"\n",
    "        分析以下论文内容并提取结构化信息：\n",
    "        {content}\n",
    "        \n",
    "        请按照以下格式提供输出：\n",
    "        {format_instructions}\n",
    "        \"\"\", input_variables=[\"content\"], partial_variables={\"format_instructions\": self.output_parser.get_format_instructions()})\n",
    "    \n",
    "    def analyze(self, content: str):\n",
    "        \"\"\"\n",
    "        分析论文内容并提取结构化信息。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 构造提示\n",
    "            prompt = self.parse_prompt_template.format(content=content)\n",
    "            \n",
    "            # 调用大语言模型获取响应\n",
    "            response = self.llm.invoke(prompt)\n",
    "            if not response or not isinstance(response, str):\n",
    "                raise ValueError(\"从模型接收到的响应无效。\")\n",
    "            \n",
    "            # 解析模型输出为结构化数据\n",
    "            structured_output = self.output_parser.parse(response)\n",
    "            \n",
    "            return structured_output\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 捕获异常并返回错误信息\n",
    "            raise RuntimeError(f\"分析论文时发生错误：{str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于评价的LLM  \n",
    "实测表现不好，不如人工评价是否有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    \"\"\"\n",
    "    定义对论文的评估结果输出格式\n",
    "    \"\"\"\n",
    "    evaluation: str = Field(description=\"论文中的方法是否适合用于本次比赛，【是】或【否】\")\n",
    "    evaluation_reason: str = Field(description=\"对论文的评估结果的解释\")\n",
    "\n",
    "class EvaluationLLM:\n",
    "    def __init__(self, model_name, api_key):\n",
    "        self.llm = Tongyi(model_name=model_name, api_key=api_key, streaming=True)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=Evaluation)\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "                <instruction>\n",
    "                请根据论文的内容，评估该论文是否适合用于本次比赛。\n",
    "                </instruction>\n",
    "                <question>\n",
    "                比赛题目：\n",
    "                在第一阶段，我们将提供 6 个风险类别（基本文本）下的有害文本查询，每个类别 30 个查询，共计 180 个查询。对于每个基本文本查询，参与者需要设计一个对抗性文本（不超过 100 个字）和一个对抗性图像，形成图像-文本对。图像-文本对的目标是触发指定的基础模型，为有害文本查询生成安全风险输出。\n",
    "                </question>\n",
    "                <paper>\n",
    "                {paper}\n",
    "                </paper>\n",
    "                <evaluation>\n",
    "                {format_instructions}\n",
    "                </evaluation>\n",
    "                \"\"\",\n",
    "            input_variables=[\"paper\"],\n",
    "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
    "        )\n",
    "\n",
    "    def evaluate(self, paper):\n",
    "        \"\"\"\n",
    "        根据论文内容生成评估结果。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 构造提示\n",
    "            prompt = self.prompt.format(paper=paper)\n",
    "            \n",
    "            # 调用大语言模型获取响应\n",
    "            raw_response = self.llm.invoke(prompt)\n",
    "            \n",
    "            if not raw_response or not isinstance(raw_response, str):\n",
    "                raise ValueError(\"从模型接收到的响应无效。\")\n",
    "            \n",
    "            # 解析模型输出为结构化数据\n",
    "            structured_output = self.parser.parse(raw_response)\n",
    "            \n",
    "            return structured_output\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 捕获异常并返回错误信息\n",
    "            raise RuntimeError(f\"评估论文时发生错误：{str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取论文、分析并保存结果\n",
    "def process_papers(folder_path, output_file, analyzer, evaluator):\n",
    "    # 读取论文内容\n",
    "    print(\"Reading papers from folder...\")\n",
    "    papers = read_papers_from_folder(folder_path)\n",
    "    \n",
    "    # 分析每篇论文并收集结果\n",
    "    results = []\n",
    "    print(\"Analyzing papers...\")\n",
    "    for paper in tqdm(papers, desc=\"Analyzing Papers\", unit=\"paper\"):\n",
    "        try:\n",
    "            # 调用 analyzer 对论文进行分析\n",
    "            structured_info = analyzer.analyze(paper)\n",
    "            # 调用 evaluator 对论文进行评估（实测表现不行）\n",
    "            # evaluation_result = evaluator.evaluate(paper)\n",
    "            # print(structured_info)\n",
    "            results.append({\n",
    "                \"title\": structured_info.title,\n",
    "                \"model_type\": structured_info.model_type,\n",
    "                \"model_names\": structured_info.model_names,\n",
    "                \"method_description\": structured_info.method_description,\n",
    "                \"main_result\": structured_info.main_result,\n",
    "                \"evaluation\": evaluation_result.evaluation,  # 是否适合用于比赛\n",
    "                \"evaluation_reason\": evaluation_result.evaluation_reason  # 评估理由\n",
    "            })\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error:{e}\")\n",
    "    \n",
    "    # 保存结果到 JSON 文件\n",
    "    print(\"Saving results to JSON file...\")\n",
    "    save_results_to_json(results, output_file)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化分析器\n",
    "analyzer = AnalyzeLLM(model_name=\"qwen-turbo\", api_key=dashscope_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化分析器（中文版）\n",
    "analyzer_cn=AnalyzeLLM_cn(model_name=\"qwen-turbo\", api_key=dashscope_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化评估器\n",
    "evaluator=EvaluationLLM(\"qwen-turbo\",dashscope_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_folder=\"../data/MLLM_attacks\"\n",
    "output_path=\"../data/output/paper_infos.json\"\n",
    "\n",
    "process_papers(papers_folder, output_path,analyzer_cn,evaluator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
